{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary modules and info\n",
    "import tweepy\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import tweepy\n",
    "import time\n",
    "import json\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "from config import (consumer_key, \n",
    "                    consumer_secret, \n",
    "                    access_token, \n",
    "                    access_token_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PullTweets(user):\n",
    "    \"\"\"Pulls 500 most recent tweets for a specified twitter user and contains them in a list\"\"\"\n",
    "    \n",
    "    # Setup Tweepy API Authentication\n",
    "    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "    auth.set_access_token(access_token, access_token_secret)\n",
    "    api = tweepy.API(auth, parser=tweepy.parsers.JSONParser())\n",
    "    \n",
    "    #set up a list containing the tweets\n",
    "    tweet_texts = []\n",
    "    \n",
    "    #create a variable to store the oldest tweet id for the loop\n",
    "    ot = None\n",
    "    \n",
    "    #loop through 25 pages (20 tweets per page) of tweets to acquire 500 tweets\n",
    "    for x in range(25):\n",
    "        tweets = api.user_timeline(user, max_id = ot)\n",
    "    \n",
    "        #loop through the tweets themselves\n",
    "        for t in tweets:\n",
    "            \n",
    "            #run Vader analysis on the tweet\n",
    "            tweet_texts.append(t['text'])\n",
    "            \n",
    "            # store the tweet id in the oldest tweet variable and subtract 1 to continue iteration\n",
    "            ot = t['id'] - 1\n",
    "            \n",
    "    return tweet_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ScoreTweets(tweet_list = []):\n",
    "    \"\"\"Runs VADER sentiment analysis on a list of tweest and enumerates them\"\"\"\n",
    "    \n",
    "    #create a list to store compound score values\n",
    "    score_list = []\n",
    "    \n",
    "    #set up a counter along with a list to contain counter values\n",
    "    c = 0\n",
    "    tweets_ago = []\n",
    "    \n",
    "    #iterate over the tweets\n",
    "    for tweet in tweet_list:\n",
    "        \n",
    "        #analyze the tweet and add compound score the list\n",
    "        score_list.append(analyzer.polarity_scores(tweet)['compound'])\n",
    "        \n",
    "        #add to counter and add to list\n",
    "        c -= 1\n",
    "        tweets_ago.append(c)\n",
    "    \n",
    "    return tweets_ago, score_list   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PlotTweets(user, timeline = [], analysis = [],):\n",
    "    \"\"\"Generates a line plot analyzing the polarity scores for the tweets previously pulled\"\"\"\n",
    "    \n",
    "    #set plot size\n",
    "    plt.figure(figsize = (10, 6))\n",
    "    \n",
    "    #plot the values contained in lists\n",
    "    plt.plot(timeline, analysis, linestyle=\":\", marker=\"o\", c=\"darkseagreen\", label=user)\n",
    "    plt.grid(color=\"0.75\", linestyle=\"-\")\n",
    "    leg = plt.legend(loc='lower center', bbox_to_anchor=(0.5, -0.25),\n",
    "              fancybox=True, shadow=True, title=\"Tweets\")\n",
    "    plt.title(f\"Tweet Sentiment for {user} as of {timestamp}\")\n",
    "    plt.xlabel(\"Tweets Ago\")\n",
    "    plt.ylabel(\"Tweet Polarity\")\n",
    "    \n",
    "    #save the figure in order to pull later\n",
    "    plt.savefig(\"Resources/Tweet_Scores.png\", bbox_extra_artists=(leg,), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TweetPlot(user, request):\n",
    "    \"\"\"Tweets out plotted sentiment analysis for a user\"\"\"\n",
    "    \n",
    "    #authorize tweepy\n",
    "    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "    auth.set_access_token(access_token, access_token_secret)\n",
    "    api = tweepy.API(auth, parser=tweepy.parsers.JSONParser())\n",
    "    \n",
    "    #send the tweet\n",
    "    api.update_with_media(\"Resources/Tweet_Scores.png\", \"New Tweet Analysis for %s (Thank you, %s!)\" % (user, request))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CheckTweets(search):\n",
    "    \"\"\"Checks user timeline to ensure no duplicates of analyses\"\"\"\n",
    "    \n",
    "    #authorize tweepy\n",
    "    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "    auth.set_access_token(access_token, access_token_secret)\n",
    "    api = tweepy.API(auth, parser=tweepy.parsers.JSONParser())\n",
    "    \n",
    "    #pull the user timeline\n",
    "    public_tweets = api.user_timeline(count=50)\n",
    "    \n",
    "    #set up a counter for how many times a substring appears in the timeline\n",
    "    counter = 0\n",
    "    \n",
    "    #check the tweets to ensure the search term has not already been mentioned\n",
    "    for tweet in public_tweets:\n",
    "        \n",
    "        if \"New Tweet Analysis for \" + search in tweet['text']:\n",
    "            counter += 1\n",
    "    #return the result\n",
    "    if counter > 0:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sourced tweets for @MomStuffPodcast at 07/27/2018 23:24\n",
      "Sentiment analysis performed.\n",
      "Visualizing sentiment analysis.\n",
      "Analysis posted!\n",
      "Analysis for @resistbot was posted recently.\n",
      "Analysis for @jk_rowling was posted recently.\n",
      "Analysis for @DaveedDiggs was posted recently.\n",
      "Scan finished. Will check again in 5 minutes.\n",
      "Sourced tweets for @ghweldon at 07/27/2018 23:30\n",
      "Sentiment analysis performed.\n",
      "Visualizing sentiment analysis.\n",
      "Analysis posted!\n",
      "Analysis for @MomStuffPodcast was posted recently.\n",
      "Analysis for @resistbot was posted recently.\n",
      "Analysis for @jk_rowling was posted recently.\n",
      "Analysis for @DaveedDiggs was posted recently.\n",
      "Scan finished. Will check again in 5 minutes.\n",
      "Sourced tweets for @samsanders at 07/27/2018 23:35\n",
      "Sentiment analysis performed.\n",
      "Visualizing sentiment analysis.\n",
      "Analysis posted!\n",
      "Analysis for @ghweldon was posted recently.\n",
      "Analysis for @MomStuffPodcast was posted recently.\n",
      "Analysis for @resistbot was posted recently.\n",
      "Analysis for @jk_rowling was posted recently.\n",
      "Analysis for @DaveedDiggs was posted recently.\n",
      "Scan finished. Will check again in 5 minutes.\n"
     ]
    }
   ],
   "source": [
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth, parser=tweepy.parsers.JSONParser())\n",
    "\n",
    "#set up the user_name to search for mentions\n",
    "target_term = \"@partofthtworld\"\n",
    "\n",
    "\n",
    "while(True):\n",
    "    \n",
    "    # Search for recent tweets\n",
    "    tweet_search = api.search(target_term, count=100, result_type=\"recent\")\n",
    "\n",
    "    #check for mentions\n",
    "    for tweet in tweet_search['statuses']:\n",
    "        \n",
    "        #check if any of the tweets contain requests for sentiment analysis\n",
    "        if \"Analyze @\" in tweet['text']:\n",
    "            requester = \"@\" + tweet[\"user\"][\"screen_name\"]\n",
    "            search_user = \"@\" + tweet['entities']['user_mentions'][1]['screen_name']\n",
    "    \n",
    "            #check if the user has been analyzed before\n",
    "            check = CheckTweets(search_user)\n",
    "\n",
    "            #if the analysis has not been run in the last 20 tweets, then run the analysis\n",
    "            if check == False:\n",
    "\n",
    "                #create a timestamp of the analysis\n",
    "                timestamp = datetime.now().strftime(\"%m/%d/%Y %H:%M\")\n",
    "\n",
    "                #pull the tweets for requested user\n",
    "                tweets = PullTweets(search_user)\n",
    "                print(f\"Sourced tweets for {search_user} at {timestamp}\")\n",
    "\n",
    "                #perform sentiment analysis on the tweet the tweets\n",
    "                scores = ScoreTweets(tweets)\n",
    "                print(\"Sentiment analysis performed.\")\n",
    "\n",
    "                #create visualization of the tweet sentiment\n",
    "                PlotTweets(search_user, scores[0], scores[1])\n",
    "                print(\"Visualizing sentiment analysis.\")\n",
    "\n",
    "                #post the analysis\n",
    "                TweetPlot(search_user, requester)\n",
    "                print(\"Analysis posted!\")\n",
    "\n",
    "            #note that the analysis has already been run\n",
    "            else:\n",
    "                print(f\"Analysis for {search_user} was posted recently.\")\n",
    "    \n",
    "    #set a timer to check every 5 minutes\n",
    "    print(\"Scan finished. Will check again in 5 minutes.\")\n",
    "    time.sleep(300)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
